# Axelix Helm Chart

* Installs [Axelix](https://github.com/axelixlabs/axelix) to Kubernetes, deploying both backend and frontend components.

## Get Repo Info

```console
helm repo add axelixlabs https://axelixlabs.github.io/helm-charts
helm repo update
```

_See [helm repo](https://helm.sh/docs/helm/helm_repo/) for command documentation._

## Installing the Chart

To install the chart with the release name `my-release`:

```console
helm install my-release axelixlabs/axelix
```

The command deploys Axelix Master on the Kubernetes cluster with the default configuration. The [Configuration](#configuration) section lists the parameters that can be configured during installation.

## Uninstalling the Chart

To uninstall/delete the my-release deployment:

```console
helm delete my-release
```

The command removes all the Kubernetes components associated with the chart and deletes the release.

## Configuration

The following table lists the configurable parameters of the Axelix Master chart and their default values.

{{ template "chart.valuesTable" . }}

## Installing the Chart with Custom Values

Specify each parameter using the `--set key=value[,key=value]` argument to `helm install`. For example:

```console
helm install my-release axelixlabs/axelix \
  --set backend.replicaCount=2 \
  --set backend.image.name=myregistry/axelix \
  --set backend.image.tag=v1.0.0 \
  --set frontend.image.name=myregistry/axelix-ui \
  --set frontend.image.tag=v1.0.0
```

Alternatively, a YAML file that specifies the values for the parameters can be provided while installing the chart. For example:

```console
helm install my-release axelixlabs/axelix -f values.yaml
```

## Backend Configuration

The backend component runs on port 8080 and handles the API endpoints. The backend service is exposed at `/api` path when ingress is enabled.

### Health Checks

The backend includes health check endpoints:
- Liveness: `/api/axelix/actuator/health/liveness`
- Readiness: `/api/axelix/actuator/health/readiness`

## Frontend Configuration

The frontend component runs on port 80 and serves the web UI. The frontend service is exposed at `/` path when ingress is enabled.

### Health Checks

The frontend includes health check endpoints:
- Liveness: `/api/axelix/actuator/health/liveness`
- Readiness: `/api/axelix/actuator/health/readiness`

## Ingress Configuration

When `ingress.enabled` is set to `true`, the chart creates an Ingress resource that routes traffic:
- `/api` path to the backend service (port 8080)
- `/` path to the frontend service (port 80)

### Example Ingress Configuration

```yaml
ingress:
  enabled: true
  className: nginx
  host: axelix.example.com
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  tls:
    enabled: true
    secretName: axelix-tls
```

## Service Accounts and RBAC

The chart can create service accounts for both backend and frontend components. The backend service account can be granted permissions via RBAC to access Kubernetes resources.

### Backend RBAC

When `rbac.autoCreateRole` is enabled, the chart creates:
- A `Role` in the `rbac.targetNamespace` with permissions to get, list, and watch pods, services, and endpoints
- A `RoleBinding` that binds the backend service account to the role

This allows the backend to monitor Kubernetes resources in the specified namespace.

## Horizontal Pod Autoscaling (HPA)

Both backend and frontend components support horizontal pod autoscaling. Enable HPA by setting `autoscaling.enabled` to `true`.

### Example HPA Configuration

```yaml
backend:
  autoscaling:
    enabled: true
    hpa:
      minReplicas: 2
      maxReplicas: 5
      targetCPU: 70
      targetMemory: 80
```

When HPA is enabled, the `replicaCount` parameter is ignored, and the deployment is managed by the HorizontalPodAutoscaler.

## Resource Management

Both backend and frontend support custom resource requests and limits. Configure resources as follows:

```yaml
backend:
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "500m"

frontend:
  resources:
    requests:
      memory: "128Mi"
      cpu: "50m"
    limits:
      memory: "256Mi"
      cpu: "200m"
```

## Node Selection and Scheduling

You can control pod placement using node selectors, affinity rules, and tolerations:

```yaml
backend:
  nodeSelector:
    kubernetes.io/os: linux
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - axelix-backend
          topologyKey: kubernetes.io/hostname
  tolerations:
  - key: "special"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
```

## Volumes and Volume Mounts

Both components support additional volumes and volume mounts:

```yaml
backend:
  volumes:
  - name: config
    configMap:
      name: axelix-backend-config
  volumeMounts:
  - name: config
    mountPath: /etc/axelix/config
    readOnly: true
```

## Image Configuration

Configure container images for both components:

```yaml
backend:
  image:
    name: "myregistry/axelix-backend"
    tag: "v1.0.0"
    pullPolicy: "IfNotPresent"

frontend:
  image:
    name: "myregistry/axelix-frontend"
    tag: "v1.0.0"
    pullPolicy: "IfNotPresent"
```

### Image Pull Secrets

If your images are in a private registry, configure image pull secrets:

```yaml
imagePullSecrets:
  - name: myregistry-secret
```
